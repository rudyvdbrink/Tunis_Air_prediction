{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data and prepare it for fitting classificaiton / regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column definitions (from project challenge description)\n",
    "\n",
    "    DATOP - Date of flight\n",
    "    FLTID - Flight number\n",
    "    DEPSTN - Departure point\n",
    "    ARRSTN - Arrival point\n",
    "    STD - Scheduled Time departure\n",
    "    STA - Scheduled Time arrival\n",
    "    STATUS - Flight status\n",
    "    ETD - Expected Time departure\n",
    "    ETA - Expected Time arrival\n",
    "    ATD - Actual Time of Departure\n",
    "    ATA - Actual Time of arrival\n",
    "    DELAY1 - Delay code 1\n",
    "    DUR1 - delay time 1\n",
    "    DELAY2 - Delay code 2\n",
    "    DUR2 - delay time 2\n",
    "    DELAY3 - Delay code 3\n",
    "    DUR3 - delay time 3\n",
    "    DELAY4 - Delay code 4\n",
    "    DUR4 - delay time 4\n",
    "    AC - Aircraft Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import supporting functions used for cleaning\n",
    "from supporting_functions import check_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('data/Train.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user-defined target for classification\n",
    "target_column = 'target'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df,target_column):\n",
    "    ### main preprocessing function:\n",
    "\n",
    "    ## done on train and test set together\n",
    "\n",
    "    #Log transform the target\n",
    "    df[target_column] = df.target.apply(lambda x: np.log1p(x) if x > 0 else 0)\n",
    "    \n",
    "    #clean up column names\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "    #check and report on duplicate data\n",
    "    df = check_duplicates(df)\n",
    "\n",
    "    ## some feature engineering\n",
    "\n",
    "    #split date into day, month, year, convert each three to number\n",
    "    df['datop'] = pd.to_datetime(df['datop'])\n",
    "    #df['year'] = df['datop'].dt.year #we cannot use year because it probably won't generalize to future years\n",
    "    df['month'] = df['datop'].dt.month\n",
    "    df['day'] = df['datop'].dt.day\n",
    "    \n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "\n",
    "    #combine STD and STA into one column with scheduled flight duration\t\n",
    "    df['std'] = pd.to_datetime(df['std'])\n",
    "    df['sta'] = pd.to_datetime(df['sta'],format='%Y-%m-%d %H.%M.%S')\n",
    "    df['flight_time'] = (df['sta'] - df['std']).dt.total_seconds() / 60 # Calculate the flight time in minutes\n",
    "\n",
    "    #save departure and arrival hour\n",
    "    df['std_hour'] = df['std'].dt.hour\n",
    "    df['sta_hour'] = df['sta'].dt.hour\n",
    "\n",
    "    # extract the letter part from 'fltid' column and create a new column 'flight_code'\n",
    "    df['flight_code'] = df['fltid'].str.split(' ').str[0]\n",
    "\n",
    "    #drop column names that we don't need\n",
    "    #df = df.drop(['id', 'fltid','std', 'sta', 'datop','ac'],axis=1)\n",
    "    df = df.drop(['id', 'fltid','std', 'sta', 'datop'],axis=1)\n",
    "    #df = df.drop(['arrstn', 'depstn', 'id', 'fltid','std', 'sta', 'datop'],axis=1)\n",
    "\n",
    "    #dummy code\n",
    "    #columns_to_dummycode = ['arrstn', 'depstn', 'status', 'flight_code'] #dummy-code arrstn, depstn, and status, ac\n",
    "    #columns_to_dummycode = ['arrstn', 'depstn', 'status', 'ac', 'flight_code'] #dummy-code arrstn, depstn, and status, ac\n",
    "    #columns_to_dummycode = ['status', 'ac', 'flight_code'] #dummy-code arrstn, depstn, and status, ac\n",
    "    #df = one_hot(df,columns_to_dummycode)\n",
    "\n",
    "    cat_columns = ['arrstn', 'depstn', 'status', 'ac', 'flight_code'] #dummy-code arrstn, depstn, and status, ac\n",
    "    df[cat_columns] = df[cat_columns].astype('category')\n",
    "\n",
    "    df.columns = [col.lower() for col in df.columns]   \n",
    "\n",
    "    \n",
    "\n",
    "    #run train-test split\n",
    "    #note: X still contains the y-variable in the 'target' column, this is because it \n",
    "    #easier to remove rows / apply cleaning steps without having to do it separately \n",
    "    #for the target data vector.\n",
    "    X = df\n",
    "    X_train, X_test, _, _ = train_test_split(X, df[target_column], random_state=0,test_size=0.2) \n",
    "\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    ## done separately for train and test\n",
    "\n",
    "    #define / identify columns for range normalization\n",
    "    columns_to_scale = df.select_dtypes(include='number').columns.drop(target_column) #identify the numeric columns\n",
    "  \n",
    "    #remove outliers from the training set\n",
    "    outlier_threshold = X_train['flight_time'].median()+(X_train['flight_time'].std()*3)\n",
    "    print(str(np.sum(X_train['flight_time'] > outlier_threshold)) + \" outliers detected\")\n",
    "    X_train = X_train[X_train['flight_time'] < outlier_threshold]\n",
    "    X_train.reset_index(drop=True, inplace=True)       \n",
    "\n",
    "    #range normalization\n",
    "    scaler = MinMaxScaler()\n",
    "    #scaler = StandardScaler()\n",
    "    scaler.set_output(transform=\"pandas\")\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train[columns_to_scale])\n",
    "    X_test_scaled  = scaler.transform(X_test[columns_to_scale])\n",
    "    X_train = pd.concat([X_train_scaled, X_train.drop(columns_to_scale,axis=1)], axis=1)\n",
    "    X_test  = pd.concat([X_test_scaled, X_test.drop(columns_to_scale,axis=1)], axis=1)\n",
    "\n",
    "    #separate the target\n",
    "    y_train = X_train.pop(target_column)\n",
    "    y_test  = X_test.pop(target_column)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data and make features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found\n",
      "38 outliers detected\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, scaler = clean_data(df,target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features and check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86228, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>flight_time</th>\n",
       "      <th>std_hour</th>\n",
       "      <th>sta_hour</th>\n",
       "      <th>depstn</th>\n",
       "      <th>arrstn</th>\n",
       "      <th>status</th>\n",
       "      <th>ac</th>\n",
       "      <th>flight_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>DJE</td>\n",
       "      <td>TUN</td>\n",
       "      <td>SCH</td>\n",
       "      <td>TU CR9ISA</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.005846</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ORN</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMM</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>MIR</td>\n",
       "      <td>DJE</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 736IOP</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>ORY</td>\n",
       "      <td>TUN</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIML</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>TUN</td>\n",
       "      <td>CAI</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TU 32AIMF</td>\n",
       "      <td>TU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      month       day  flight_time  std_hour  sta_hour depstn arrstn status   \n",
       "0  0.000000  0.666667     0.003077  0.652174  0.695652    DJE    TUN    SCH  \\\n",
       "1  0.545455  0.766667     0.005846  0.304348  0.391304    TUN    ORN    ATA   \n",
       "2  0.909091  0.800000     0.002154  0.913043  0.956522    MIR    DJE    ATA   \n",
       "3  0.636364  0.033333     0.008308  0.260870  0.347826    ORY    TUN    ATA   \n",
       "4  0.909091  0.166667     0.010462  0.608696  0.739130    TUN    CAI    ATA   \n",
       "\n",
       "          ac flight_code  \n",
       "0  TU CR9ISA          UG  \n",
       "1  TU 32AIMM          TU  \n",
       "2  TU 736IOP          TU  \n",
       "3  TU 32AIML          TU  \n",
       "4  TU 32AIMF          TU  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86228 entries, 0 to 86227\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   month        86228 non-null  float64 \n",
      " 1   day          86228 non-null  float64 \n",
      " 2   flight_time  86228 non-null  float64 \n",
      " 3   std_hour     86228 non-null  float64 \n",
      " 4   sta_hour     86228 non-null  float64 \n",
      " 5   depstn       86228 non-null  category\n",
      " 6   arrstn       86228 non-null  category\n",
      " 7   status       86228 non-null  category\n",
      " 8   ac           86228 non-null  category\n",
      " 9   flight_code  86228 non-null  category\n",
      "dtypes: category(5), float64(5)\n",
      "memory usage: 3.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in case we want to do feature filtering, we can un-comment the code below\n",
    "\n",
    "discarded_features = []\n",
    "#select features with filtering\n",
    "# thresh = 0.95 #remove features that correlate above this threshold\n",
    "#X_train, X_test, discarded_features = filter_features(X_train,X_test,thresh)\n",
    "\n",
    "#plot correlation between regressors\n",
    "# sns.heatmap(X_train.corr(),vmin=-1,vmax=1,cmap='seismic')\n",
    "# plt.title('Correlations in design matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save everything to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = [X_train, X_test, y_train, y_test, discarded_features, scaler]\n",
    "\n",
    "# save data to file so we don't have to run it again\n",
    "with open('data/clean_data.pkl','wb') as f:\n",
    "    pickle.dump(data_to_save,f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
